{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CDH-yGDxTVc2"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence, unpad_sequence, pack_sequence, pad_packed_sequence\n",
        "from torchmetrics.classification import BinaryF1Score\n",
        "from tqdm.auto import tqdm\n",
        "import wandb\n",
        "\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "RANDOM_SEED = 1\n",
        "DEV = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q5JNNwUeTVc3"
      },
      "outputs": [],
      "source": [
        "class OsuDataset:\n",
        "    \"\"\"\n",
        "    Beatmap + audio dataset.\n",
        "    GETITEM: specs, beat_phase, beat_num, difficulty, onsets, actions\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, beatmap_path, audio_path):\n",
        "        self.beatmap_fns = sorted(list(beatmap_path.glob('*.pt')))\n",
        "        self.audio_fns = sorted(list(audio_path.glob('*.pt')))\n",
        "        print('Loading dataset...', end='')\n",
        "        self.beatmap_stems = [fn.stem.split('-')[0] for fn in self.beatmap_fns]\n",
        "        self.beatmaps = [torch.load(fn) for fn in self.beatmap_fns]\n",
        "        self.audio_stems = [fn.stem for fn in self.audio_fns]\n",
        "        self.audio = [torch.load(fn) for fn in self.audio_fns]\n",
        "        print('Done')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.beatmaps)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            audio_idx = self.audio_stems.index(self.beatmap_stems[idx])\n",
        "        except ValueError:\n",
        "            raise FileNotFoundError(f'Audio file not found for {self.beatmap_stems[idx]}')\n",
        "            \n",
        "        actions, onsets, _, difficulty = self.beatmaps[idx].values()\n",
        "        specs, beat_phase, beat_num = self.audio[audio_idx].values()\n",
        "\n",
        "        # randomly slice data to 30s\n",
        "        if specs.shape[1] > 3001:\n",
        "            start = random.randint(0, specs.shape[1] - 3001)\n",
        "            actions = actions[start:start+3001]\n",
        "            onsets = onsets[start+1:start+3001]\n",
        "            specs = specs[:, start+1:start+3001, :]\n",
        "            beat_phase = beat_phase[start+1:start+3001]\n",
        "            beat_num = beat_num[start+1:start+3001]\n",
        "            difficulty = (torch.FloatTensor([difficulty]) * 0.2).expand(3000).unsqueeze(-1)\n",
        "        else:\n",
        "            raise IndexError(f'Beatmap shorter than 30s: {self.beatmap_stems[idx]}')\n",
        "\n",
        "        return specs, beat_phase, beat_num, difficulty, onsets, actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yEMh_mkbTVc4"
      },
      "outputs": [],
      "source": [
        "class PadCollater:\n",
        "    def __call__(self, batch):\n",
        "        specs = []\n",
        "        beat_phases = []\n",
        "        beat_nums = []\n",
        "        difficulties = []\n",
        "        onsets = []\n",
        "        actions = []\n",
        "\n",
        "        for x in batch:\n",
        "            specs.append(x[0])\n",
        "            beat_phases.append(x[1])\n",
        "            beat_nums.append(x[2])\n",
        "            difficulties.append(x[3])\n",
        "            onsets.append(x[4])\n",
        "            actions.append(x[5])\n",
        "\n",
        "        specs = torch.stack(specs)\n",
        "        beat_phases = torch.stack(beat_phases)\n",
        "        beat_nums = torch.stack(beat_nums)\n",
        "        difficulties = torch.stack(difficulties)\n",
        "        onsets = torch.stack(onsets)\n",
        "        actions = torch.stack(actions)\n",
        "\n",
        "        return specs, beat_phases, beat_nums, difficulties, onsets, actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sg2UsI7sTVc4"
      },
      "outputs": [],
      "source": [
        "class OsuModel(nn.Module):\n",
        "    def __init__(self, device, bp_emb_dim=16, bn_emb_dim=8, diff_emb_dim=8,\n",
        "                 np_hidden_size=256, np_num_layers=2, ns_pre_proj_size=32,\n",
        "                 ns_hidden_size=256, ns_num_layers=2, num_tokens=256):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.gelu = nn.GELU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.conv = nn.Conv2d(in_channels=3,\n",
        "                              out_channels=1,\n",
        "                              kernel_size=(15, 5),\n",
        "                              padding='same')\n",
        "        self.beat_phase_emb = nn.Embedding(49, bp_emb_dim)\n",
        "        self.beat_num_emb = nn.Embedding(4, bn_emb_dim)\n",
        "        self.difficulty_emb = nn.Embedding(21, diff_emb_dim)\n",
        "\n",
        "        self.np_gru = nn.GRU(input_size=80 + bp_emb_dim + bn_emb_dim + diff_emb_dim,\n",
        "                             hidden_size=np_hidden_size,\n",
        "                             num_layers=np_num_layers,\n",
        "                             batch_first=True,\n",
        "                             bidirectional=True)\n",
        "        self.np_proj_1 = nn.Linear(np_hidden_size*2, 128)\n",
        "        self.np_proj_2 = nn.Linear(128, 1)\n",
        "\n",
        "        self.ns_pre_proj = nn.Linear(128, ns_pre_proj_size)\n",
        "        self.ns_gru = nn.GRU(input_size=80 + ns_pre_proj_size + bp_emb_dim + bn_emb_dim + diff_emb_dim,\n",
        "                             hidden_size=ns_hidden_size,\n",
        "                             num_layers=ns_num_layers,\n",
        "                             batch_first=True,\n",
        "                             bidirectional=False)\n",
        "        self.ns_proj_1 = nn.Linear(ns_hidden_size, ns_hidden_size)\n",
        "        self.ns_proj_2 = nn.Linear(ns_hidden_size, num_tokens)\n",
        "\n",
        "    def forward(self, specs, beat_phases, beat_nums, difficulties, lengths):\n",
        "        conv_outs = [self.gelu(self.conv(spec)).squeeze() for spec in specs]\n",
        "        bp_emb = unpad_sequence(self.beat_phase_emb(beat_phases).to('cpu'),\n",
        "                                lengths.to('cpu'), batch_first=True)\n",
        "        bn_emb = unpad_sequence(self.beat_num_emb(beat_nums).to('cpu'),\n",
        "                                lengths.to('cpu'), batch_first=True)\n",
        "        diff = difficulties.unsqueeze(1).expand(-1, lengths.max().item())\n",
        "        diff_emb = unpad_sequence(self.difficulty_emb(diff).to('cpu'),\n",
        "                                  lengths.to('cpu'), batch_first=True)\n",
        "\n",
        "        # ========== Note Placement ========== #\n",
        "\n",
        "        np_in = []\n",
        "        for i in range(len(lengths)):\n",
        "            np_in.append(torch.cat([conv_outs[i],\n",
        "                                    bp_emb[i].to(self.device),\n",
        "                                    bn_emb[i].to(self.device),\n",
        "                                    diff_emb[i].to(self.device)],\n",
        "                                   dim=-1))\n",
        "        np_in_packed = pack_sequence(np_in, enforce_sorted=False)\n",
        "        np_out, last_hidden = self.np_gru(np_in_packed)\n",
        "        np_out_padded, _ = pad_packed_sequence(np_out, batch_first=True)\n",
        "\n",
        "        np_proj_1_out = self.gelu(self.np_proj_1(np_out_padded))\n",
        "        np_pred = self.sigmoid(self.np_proj_2(np_proj_1_out)).squeeze()\n",
        "\n",
        "        # ========== Note Selection ========== #\n",
        "\n",
        "        ns_pre_proj_padded = self.ns_pre_proj(np_proj_1_out)\n",
        "        ns_pre_proj = unpad_sequence(ns_pre_proj_padded, lengths, batch_first=True)\n",
        "        ns_in = []\n",
        "        for i in range(len(lengths)):\n",
        "            ns_in.append(torch.cat([conv_outs[i],\n",
        "                                    ns_pre_proj[i],\n",
        "                                    bp_emb[i].to(self.device),\n",
        "                                    bn_emb[i].to(self.device),\n",
        "                                    diff_emb[i].to(self.device)],\n",
        "                                   dim=-1))\n",
        "        ns_in_packed = pack_sequence(ns_in, enforce_sorted=False)\n",
        "        ns_out, last_hidden = self.ns_gru(ns_in_packed)\n",
        "        ns_out_padded, _ = pad_packed_sequence(ns_out, batch_first=True)\n",
        "\n",
        "        ns_proj_1_out = self.gelu(self.ns_proj_1(ns_out_padded))\n",
        "        ns_logit = self.ns_proj_2(ns_proj_1_out)\n",
        "\n",
        "        return np_pred, ns_logit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ConvStack Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StackModel(nn.Module):\n",
        "    def __init__(self, bp_emb_dim=16, bn_emb_dim=8, diff_emb_dim=8,\n",
        "                 np_hidden_size=256, np_num_layers=2, ns_pre_proj_size=32,\n",
        "                 ns_hidden_size=256, ns_num_layers=2,\n",
        "                 num_tokens=256, action_emb_dim=32):\n",
        "        super().__init__()\n",
        "        self.gelu = nn.GELU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.stack = nn.Sequential(\n",
        "            nn.Conv2d(3, 8, (5, 3), stride=(1, 2), padding=(2, 1)),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, (5, 3), stride=(1, 2), padding=(2, 1)),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, (5, 3), stride=(1, 2), padding=(2, 1)),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, (5, 3), stride=(1, 2), padding=(2, 1)),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.beat_phase_emb = nn.Embedding(49, bp_emb_dim)\n",
        "        self.beat_num_emb = nn.Embedding(4, bn_emb_dim)\n",
        "        self.difficulty_proj = nn.Sequential(\n",
        "            nn.Linear(1, diff_emb_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(diff_emb_dim, diff_emb_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.action_emb = nn.Embedding(num_tokens, action_emb_dim)\n",
        "\n",
        "        self.np_gru = nn.GRU(input_size=320 + bp_emb_dim + bn_emb_dim + diff_emb_dim,\n",
        "                             hidden_size=np_hidden_size,\n",
        "                             num_layers=np_num_layers,\n",
        "                             batch_first=True,\n",
        "                             bidirectional=True)\n",
        "        self.np_proj_1 = nn.Linear(np_hidden_size*2, 128)\n",
        "        self.np_proj_2 = nn.Linear(128, 1)\n",
        "\n",
        "        self.ns_pre_proj = nn.Linear(128, ns_pre_proj_size)\n",
        "        self.ns_gru = nn.GRU(input_size=320 + ns_pre_proj_size + bp_emb_dim + bn_emb_dim + diff_emb_dim + action_emb_dim,\n",
        "                             hidden_size=ns_hidden_size,\n",
        "                             num_layers=ns_num_layers,\n",
        "                             batch_first=True,\n",
        "                             bidirectional=False)\n",
        "        self.ns_proj_1 = nn.Linear(ns_hidden_size, ns_hidden_size)\n",
        "        self.ns_proj_2 = nn.Linear(ns_hidden_size, num_tokens)\n",
        "\n",
        "    def forward(self, specs, beat_phases, beat_nums, difficulties, actions):\n",
        "        conv_outs = self.stack(specs)\n",
        "        conv_outs = conv_outs.permute(0, 2, 1, 3).reshape(conv_outs.shape[0], conv_outs.shape[2], -1)\n",
        "        bp_emb = self.beat_phase_emb(beat_phases)\n",
        "        bn_emb = self.beat_num_emb(beat_nums)\n",
        "        diff_proj = self.difficulty_proj(difficulties)\n",
        "\n",
        "        # ========== Note Placement ========== #\n",
        "        np_in = torch.cat([conv_outs, bp_emb, bn_emb, diff_proj], dim=-1)\n",
        "        np_out, last_hidden = self.np_gru(np_in)\n",
        "\n",
        "        np_proj_1_out = self.gelu(self.np_proj_1(np_out))\n",
        "        np_pred = self.sigmoid(self.np_proj_2(np_proj_1_out)).squeeze()\n",
        "\n",
        "        # ========== Note Selection ========== #\n",
        "        ns_pre_proj = self.gelu(self.ns_pre_proj(np_proj_1_out))\n",
        "        action_emb = self.action_emb(actions)\n",
        "        ns_in = torch.cat(\n",
        "            [conv_outs, ns_pre_proj, bp_emb, bn_emb, diff_proj, action_emb], dim=-1)\n",
        "        ns_out, ns_last_hidden = self.ns_gru(ns_in)\n",
        "\n",
        "        ns_proj_1_out = self.gelu(self.ns_proj_1(ns_out))\n",
        "        ns_logit = self.ns_proj_2(ns_proj_1_out)\n",
        "\n",
        "        return np_pred, ns_logit, ns_last_hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def infer(model, specs, beat_phases, beat_nums, difficulties, device):\n",
        "    specs = specs.to(device)\n",
        "    beat_phases = beat_phases.to(device)\n",
        "    beat_nums = beat_nums.to(device)\n",
        "    difficulties = difficulties.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        conv_outs = model.stack(specs)\n",
        "        conv_outs = conv_outs.permute(0, 2, 1, 3).flatten(2,3)\n",
        "        bp_emb = model.beat_phase_emb(beat_phases)\n",
        "        bn_emb = model.beat_num_emb(beat_nums)\n",
        "        diff_proj = model.difficulty_proj(difficulties)\n",
        "\n",
        "        np_in = torch.cat([conv_outs, bp_emb, bn_emb, diff_proj], dim=-1)\n",
        "        np_out, _ = model.np_gru(np_in)\n",
        "        np_proj_1_out = model.gelu(model.np_proj_1(np_out))\n",
        "        ns_pre_proj = model.gelu(model.ns_pre_proj(np_proj_1_out))\n",
        "        \n",
        "        out = torch.zeros([specs.shape[0], specs.shape[2]], device=device)\n",
        "        action_emb = model.action_emb(torch.zeros([specs.shape[0], 1], device=device, dtype=torch.long))\n",
        "        last_hidden = torch.zeros([2, specs.shape[0], 256], device=device)\n",
        "\n",
        "        ns_in = torch.cat([conv_outs, ns_pre_proj, bp_emb, bn_emb, diff_proj], dim=-1)\n",
        "        for i in range(specs.shape[2]):\n",
        "            ns_in_temp = torch.cat([ns_in[:, i:i+1], action_emb], -1) # N x 1 x C\n",
        "            ns_out, last_hidden = model.ns_gru(ns_in_temp, last_hidden)\n",
        "            ns_proj_1_out = model.gelu(model.ns_proj_1(ns_out))\n",
        "            ns_logit = model.ns_proj_2(ns_proj_1_out)\n",
        "            ns_pred = ns_logit.argmax(dim=-1)\n",
        "            out[:, i] = ns_pred\n",
        "            action_emb = model.action_emb(ns_pred)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "bm = torch.load('osu_dataset/test/1893984-211-4.pt')\n",
        "a = torch.load('osu_dataset/test/1893984.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions, onsets, _, difficulty = bm.values()\n",
        "difficulty = 16\n",
        "specs, beat_phase, beat_num = a.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "out = infer(model, specs.unsqueeze(0), beat_phase.unsqueeze(0), beat_num.unsqueeze(0), (torch.FloatTensor([difficulty]) * 0.2).expand(specs.shape[1]).unsqueeze(-1).unsqueeze(0), DEV).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 long note start\n",
            "1 long note end\n",
            "3 long note start\n",
            "3 long note end\n",
            "1 long note start\n",
            "1 long note end\n",
            "0 long note start\n",
            "0 long note end\n",
            "2 long note start\n",
            "2 long note end\n",
            "1 long note start\n",
            "1 long note end\n",
            "0 long note start\n",
            "0 long note end\n",
            "1 long note start\n",
            "1 long note end\n",
            "2 long note start\n",
            "2 long note end\n",
            "1 long note start\n",
            "1 long note end\n",
            "2 long note start\n",
            "2 long note end\n",
            "2 long note start\n",
            "2 long note end\n",
            "2 long note start\n",
            "2 long note end\n",
            "2 long note start\n",
            "2 long note end\n",
            "3 long note start\n",
            "3 long note end\n"
          ]
        }
      ],
      "source": [
        "from utils import index_to_combination\n",
        "\n",
        "beatmap = []\n",
        "for i, token in enumerate(out):\n",
        "    if token.item() > 0:\n",
        "        key0, key1, key2, key3 = index_to_combination(token.item(), 4)\n",
        "        beatmap.append([i * 10, key0, key1, key2, key3])\n",
        "\n",
        "beatmap_str_list = []\n",
        "long = [False, False, False, False]\n",
        "long_start = [[], [], [], []]\n",
        "long_end = [[], [], [], []]\n",
        "line_num = 0\n",
        "for timestep_idx, action in enumerate(beatmap):\n",
        "    time = action[0]\n",
        "    keys = action[1:]\n",
        "    for key, token in enumerate(keys):\n",
        "        if token > 0:\n",
        "            xpos = 64 + key * 128\n",
        "            if token == 2:\n",
        "                print(f'{key} long note start')\n",
        "                long_start[key].append(line_num)\n",
        "                beatmap_str_list.append(f'{xpos},192,{time},128,2,')\n",
        "                long[key] = True\n",
        "            elif token == 3 and long[key] == True:\n",
        "                print(f'{key} long note end')\n",
        "                long_end[key].append(time)\n",
        "                long[key] = False\n",
        "                break\n",
        "            else:\n",
        "                beatmap_str_list.append(f'{xpos},192,{time},1,0,0:0:0:0:')\n",
        "            line_num += 1\n",
        "\n",
        "for start_key, l in enumerate(long_start):\n",
        "    for i, line_num in enumerate(l):\n",
        "        endtime = long_end[start_key][i]\n",
        "        beatmap_str_list[line_num] = f'{beatmap_str_list[line_num]}{endtime}:0:0:0:0:'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "file = open(Path('osu_dataset/test/inference.txt'), 'w')\n",
        "file.write('\\n'.join(beatmap_str_list))\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JwWVNivfTVc5"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, optimizer, train_loader,\n",
        "                 valid_loader, device, checkpoint_path: Path,\n",
        "                 np_fl_gamma=2, np_fl_weight=0.8,\n",
        "                 ns_fl_gamma=2, ns_fl_weight=0.8,\n",
        "                 np_loss_multiplier=7):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.valid_loader = valid_loader\n",
        "        self.device = device\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "        checkpoint_path.mkdir(exist_ok=True)\n",
        "        self.np_fl_gamma = np_fl_gamma\n",
        "        self.np_fl_weight = np_fl_weight\n",
        "        self.ns_fl_gamma = ns_fl_gamma\n",
        "        self.ns_fl_weight = ns_fl_weight\n",
        "        self.np_loss_multiplier = np_loss_multiplier\n",
        "        self.start_epoch = 0\n",
        "        self.f1 = BinaryF1Score().to(self.device)\n",
        "        # TODO: metrics (Perplexity, F-score, AUC...)\n",
        "\n",
        "    def load_checkpoint(self, fn):\n",
        "        checkpoint = torch.load(fn, map_location=self.device)\n",
        "        self.start_epoch = checkpoint['epoch'] + 1\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        for state in self.optimizer.state.values():\n",
        "            for k, v in state.items():\n",
        "                if (torch.is_tensor(v)):\n",
        "                    state[k] = v.to(self.device)\n",
        "\n",
        "    def save_checkpoint(self, epoch, fn):\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict()\n",
        "        }\n",
        "        torch.save(checkpoint, fn)\n",
        "\n",
        "    def binary_focal_loss(self, y, pred, gamma, pos_weight):\n",
        "        \"\"\"\n",
        "        Biary focal loss for when y=1 is the minority class.\\n\n",
        "        INPUT\n",
        "            gamma: factor for suppressing loss for easy examples (gamma > 1)\n",
        "            pos_weight: how much to suppress loss when y=0 (0 <= pos_weight <= 1)\n",
        "        \"\"\"\n",
        "        return -(y * (1-pred).pow(gamma) * pred.log() +\n",
        "                 pos_weight * (1-y) * pred.pow(gamma) * (1-pred).log()).mean()\n",
        "\n",
        "    def multi_focal_loss(self, y, pred, gamma, pos_weight):\n",
        "        \"\"\"\n",
        "        Multi-class focal loss for when y=0 is the majority class.\\n\n",
        "        INPUT\n",
        "            gamma: factor for suppressing loss for easy examples (gamma > 1)\n",
        "            pos_weight: how much to suppress loss when y=0 (0 <= pos_weight <= 1)\n",
        "        \"\"\"\n",
        "        p_y = pred[torch.arange(len(pred)), y]\n",
        "        weight_mask = torch.where(y == 0, pos_weight, 1)\n",
        "        return -(weight_mask * (1 - p_y).pow(gamma) * p_y.log()).mean()\n",
        "\n",
        "    def train(self, num_epochs, log_to_wandb=True, hyperparams=None):\n",
        "        if log_to_wandb:\n",
        "            wandb.init(project='AutoOsu', config=hyperparams)\n",
        "            \n",
        "        self.model.to(self.device)\n",
        "        for epoch in tqdm(range(self.start_epoch, num_epochs)):\n",
        "            self.model.train()\n",
        "            for batch in tqdm(self.train_loader, leave=False):\n",
        "                specs, beat_phases, beat_nums, difficulties, onsets, actions = batch\n",
        "                specs = specs.to(self.device)\n",
        "                beat_phases = beat_phases.to(self.device)\n",
        "                beat_nums = beat_nums.to(self.device)\n",
        "                difficulties = difficulties.to(self.device)\n",
        "                onsets = onsets.to(self.device)\n",
        "                actions_gt = actions[:, 1:].to(self.device)\n",
        "                actions_shifted = actions[:, :-1].to(self.device)\n",
        "\n",
        "                np_pred, ns_logit, _ = self.model(\n",
        "                    specs, beat_phases, beat_nums, difficulties, actions_shifted)\n",
        "\n",
        "                np_pred = torch.reshape(np_pred, [-1])\n",
        "                np_label = torch.reshape(onsets, [-1])\n",
        "\n",
        "                ns_pred = torch.reshape(\n",
        "                    ns_logit, [-1, ns_logit.shape[-1]]).softmax(dim=-1)\n",
        "                ns_label = torch.reshape(actions_gt, [-1])\n",
        "\n",
        "                np_loss = self.binary_focal_loss(\n",
        "                    np_label, np_pred, self.np_fl_gamma, self.np_fl_weight) * self.np_loss_multiplier\n",
        "                ns_loss = self.multi_focal_loss(\n",
        "                    ns_label, ns_pred, self.ns_fl_gamma, self.ns_fl_weight)\n",
        "\n",
        "                batch_loss = np_loss + ns_loss\n",
        "                self.optimizer.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                ns_acc = (ns_pred.argmax(dim=-1) == ns_label).float().mean()\n",
        "                if log_to_wandb:\n",
        "                    wandb.log({'train_np_loss': np_loss.item(),\n",
        "                            'train_ns_loss': ns_loss.item(),\n",
        "                            'train_loss': batch_loss.item(),\n",
        "                            'train_acc': ns_acc.item(),\n",
        "                            'train_np_f1': self.f1(np_pred, np_label.int()).item()})\n",
        "\n",
        "            self.model.eval()\n",
        "            with torch.inference_mode():\n",
        "                valid_np_loss_sum = 0\n",
        "                valid_ns_loss_sum = 0\n",
        "                valid_loss_sum = 0\n",
        "                valid_np_f1_sum = 0\n",
        "                valid_ns_acc_sum = 0\n",
        "                for batch in tqdm(self.valid_loader, leave=False):\n",
        "                    specs, beat_phases, beat_nums, difficulties, onsets, actions = batch\n",
        "                    specs = specs.to(self.device)\n",
        "                    beat_phases = beat_phases.to(self.device)\n",
        "                    beat_nums = beat_nums.to(self.device)\n",
        "                    difficulties = difficulties.to(self.device)\n",
        "                    onsets = onsets.to(self.device)\n",
        "                    actions_gt = actions[:, 1:].to(self.device)\n",
        "                    actions_shifted = actions[:, :-1].to(self.device)\n",
        "\n",
        "                    np_pred, ns_logit, _ = self.model(\n",
        "                        specs, beat_phases, beat_nums, difficulties, actions_shifted)\n",
        "\n",
        "                    np_pred = torch.reshape(np_pred, [-1])\n",
        "                    np_label = torch.reshape(onsets, [-1])\n",
        "\n",
        "                    ns_pred = torch.reshape(\n",
        "                        ns_logit, [-1, ns_logit.shape[-1]]).softmax(dim=-1)\n",
        "                    ns_label = torch.reshape(actions_gt, [-1])\n",
        "\n",
        "                    np_loss = self.binary_focal_loss(\n",
        "                        np_label, np_pred, self.np_fl_gamma, self.np_fl_weight) * self.np_loss_multiplier\n",
        "                    ns_loss = self.multi_focal_loss(\n",
        "                        ns_label, ns_pred, self.ns_fl_gamma, self.ns_fl_weight)\n",
        "\n",
        "                    batch_loss = np_loss + ns_loss\n",
        "                    valid_np_loss_sum += np_loss.item()\n",
        "                    valid_ns_loss_sum += ns_loss.item()\n",
        "                    valid_loss_sum += batch_loss.item()\n",
        "                    ns_acc = (ns_pred.argmax(dim=-1) ==\n",
        "                              ns_label).float().mean()\n",
        "                    valid_ns_acc_sum += ns_acc.item()\n",
        "                    valid_np_f1_sum += self.f1(np_pred, np_label.int()).item()\n",
        "\n",
        "                if log_to_wandb:\n",
        "                    wandb.log({'valid_np_loss': valid_np_loss_sum / len(self.valid_loader),\n",
        "                            'valid_ns_loss': valid_ns_loss_sum / len(self.valid_loader),\n",
        "                            'valid_loss': valid_loss_sum / len(self.valid_loader),\n",
        "                            'valid_acc': valid_ns_acc_sum / len(self.valid_loader),\n",
        "                            'valid_np_f1': valid_np_f1_sum / len(self.valid_loader)})\n",
        "\n",
        "            time = datetime.now().strftime('%m-%d-%H-%M-%S')\n",
        "            checkpoint_path = Path(\n",
        "                self.checkpoint_path / f'{time}-epoch{epoch}.pt')\n",
        "            self.save_checkpoint(epoch, checkpoint_path)\n",
        "\n",
        "        if log_to_wandb:\n",
        "            wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fHxvv0EkTVc6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">15</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span>valid_loader = torch.utils.data.DataLoader(                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>valid_set, batch_size=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>, shuffle=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, collate_fn=collater, drop_last=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>15 model = OsuModel(device=DEV)                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span>optimizer = torch.optim.Adam(model.parameters(), lr=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1e-3</span>)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span>trainer = Trainer(model, optimizer, train_loader, valid_loader,                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │     </span>device=DEV, checkpoint_path=Path(<span style=\"color: #808000; text-decoration-color: #808000\">'checkpoints'</span>),                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'OsuModel'</span> is not defined\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m15\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0mvalid_loader = torch.utils.data.DataLoader(                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   \u001b[0mvalid_set, batch_size=\u001b[94m4\u001b[0m, shuffle=\u001b[94mFalse\u001b[0m, collate_fn=collater, drop_last=\u001b[94mTrue\u001b[0m)            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m15 model = OsuModel(device=DEV)                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0moptimizer = torch.optim.Adam(model.parameters(), lr=\u001b[94m1e-3\u001b[0m)                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0mtrainer = Trainer(model, optimizer, train_loader, valid_loader,                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   │   │   │     \u001b[0mdevice=DEV, checkpoint_path=Path(\u001b[33m'\u001b[0m\u001b[33mcheckpoints\u001b[0m\u001b[33m'\u001b[0m),                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'OsuModel'\u001b[0m is not defined\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "beatmap_path = Path('osu_dataset/beatmap/4keys/')\n",
        "audio_path = Path('osu_dataset/audio/')\n",
        "\n",
        "base_set = OsuDataset(beatmap_path, audio_path)\n",
        "generator = torch.Generator().manual_seed(RANDOM_SEED)\n",
        "train_set, valid_set = torch.utils.data.random_split(\n",
        "    base_set, [0.95, 0.5], generator)\n",
        "\n",
        "collater = PadCollater()\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=12, shuffle=True, generator=generator, collate_fn=collater, drop_last=True)\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    valid_set, batch_size=4, shuffle=False, collate_fn=collater, drop_last=True)\n",
        "\n",
        "model = OsuModel(device=DEV)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "trainer = Trainer(model, optimizer, train_loader, valid_loader,\n",
        "                  device=DEV, checkpoint_path=Path('checkpoints'),\n",
        "                  ns_fl_gamma=2, ns_fl_weight=0.8,\n",
        "                  np_fl_gamma=3, np_fl_weight=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train ConvStack Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hyperparams = {\n",
        "    'bp_emb_dim': 32,\n",
        "    'bn_emb_dim': 16,\n",
        "    'diff_emb_dim': 16,\n",
        "    'np_hidden_size': 256,\n",
        "    'np_num_layers': 2,\n",
        "    'ns_pre_proj_size': 32,\n",
        "    'ns_hidden_size': 256,\n",
        "    'ns_num_layers': 2,\n",
        "    'action_emb_dim': 32,\n",
        "    'np_fl_gamma': 2,\n",
        "    'np_fl_weight': 0.8,\n",
        "    'ns_fl_gamma': 3,\n",
        "    'ns_fl_weight': 0.5,\n",
        "    'learning_rate': 5e-4,\n",
        "    'batch_size': 24,\n",
        "    'num_epochs': 180\n",
        "}\n",
        "\n",
        "beatmap_path = Path('osu_dataset/beatmap/4keys/')\n",
        "audio_path = Path('osu_dataset/audio/')\n",
        "\n",
        "base_set = OsuDataset(beatmap_path, audio_path)\n",
        "generator = torch.Generator().manual_seed(RANDOM_SEED)\n",
        "train_set, valid_set = torch.utils.data.random_split(\n",
        "    base_set, [0.95, 0.05], generator)\n",
        "\n",
        "collater = PadCollater()\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=hyperparams['batch_size'], shuffle=True, generator=generator, collate_fn=collater, drop_last=False)\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    valid_set, batch_size=12, shuffle=False, collate_fn=collater, drop_last=False)\n",
        "\n",
        "model = StackModel(bp_emb_dim=hyperparams['bp_emb_dim'],\n",
        "                   bn_emb_dim=hyperparams['bn_emb_dim'],\n",
        "                   diff_emb_dim=hyperparams['diff_emb_dim'],\n",
        "                   np_hidden_size=hyperparams['np_hidden_size'],\n",
        "                   np_num_layers=hyperparams['np_num_layers'],\n",
        "                   ns_pre_proj_size=hyperparams['ns_pre_proj_size'],\n",
        "                   ns_hidden_size=hyperparams['ns_hidden_size'],\n",
        "                   ns_num_layers=hyperparams['ns_num_layers'],\n",
        "                   num_tokens=256,\n",
        "                   action_emb_dim=hyperparams['action_emb_dim'])\n",
        "                   \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams['learning_rate'])\n",
        "trainer = Trainer(model, optimizer, train_loader, valid_loader,\n",
        "                  device=DEV, checkpoint_path=Path('checkpoints/convstack/'),\n",
        "                  np_fl_gamma=hyperparams['np_fl_gamma'], np_fl_weight=hyperparams['np_fl_weight'],\n",
        "                  ns_fl_gamma=hyperparams['ns_fl_gamma'], ns_fl_weight=hyperparams['ns_fl_weight'])\n",
        "\n",
        "trainer.train(hyperparams['num_epochs'], log_to_wandb=True, hyperparams=hyperparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.init(project='AutoOsu', id='wwjh1mq4', resume='must')\n",
        "trainer.start_epoch = 40\n",
        "trainer.train(60)\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
