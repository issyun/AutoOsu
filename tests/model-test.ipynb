{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note Placement Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "is_macos = platform == 'darwin'\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeatmapConverter:\n",
    "    def __init__(self,\n",
    "                audio_dir:Path, \n",
    "                osu_dir:Path, \n",
    "                data_dir:Path, \n",
    "                n_fft_list:list=[1024, 2048, 4096],\n",
    "                hop_ms:int=10,\n",
    "                context_window_size = 7):\n",
    "        self.audio_fns = sorted([p for p in Path(audio_dir).glob('**/*') if p.suffix in {'.mp3', '.wav', '.ogg'}])\n",
    "        self.osu_fns = sorted(list(Path(osu_dir).rglob('*.osu')))\n",
    "        self.data_dir = data_dir\n",
    "        self.hop_length = int(44100 * (hop_ms / 1000))\n",
    "        self.melspec_converters = [ torchaudio.transforms.MelSpectrogram(sample_rate=44100,\n",
    "                                                                        n_fft=n_fft, \n",
    "                                                                        hop_length=self.hop_length, \n",
    "                                                                        f_max=11000, \n",
    "                                                                        n_mels=80,\n",
    "                                                                        power=2) \n",
    "                                                                        for n_fft in n_fft_list ]\n",
    "        self.context_window_size = context_window_size\n",
    "\n",
    "    def get_beat_phase(self, note_time, beat_length:float, offset:float):\n",
    "        return ((note_time - offset) % beat_length) / beat_length\n",
    "\n",
    "    def parse_beatmap(self, fn):\n",
    "        # Extract beatmap information from an .osu file.\n",
    "        # RETURNS: Int: num_keys, FloatTensor: num_notes X 4(time, key_number, note_type, beat_phase).\n",
    "        #          -1 if error.\n",
    "\n",
    "        with open(fn, mode='r', encoding='utf-8') as f:\n",
    "            raw_content = f.read().splitlines()\n",
    "\n",
    "        timing_points = []\n",
    "        # Read everything until next section\n",
    "        i = raw_content.index('[TimingPoints]') + 1\n",
    "        while raw_content[i] != '' and raw_content[i][0] != '[':\n",
    "            timing_points.append(raw_content[i])\n",
    "            i += 1\n",
    "\n",
    "        # Check if multiple BPMs exist\n",
    "        beat_lengths = {float(tp.split(',')[1]) for tp in timing_points if float(tp.split(',')[1]) > 0}\n",
    "        if len(beat_lengths) > 1:\n",
    "            print(f'Multiple BPMs in file {fn.name}: skipping conversion.')\n",
    "            return -1, -1\n",
    "\n",
    "        offset = float(timing_points[0].split(',')[0])\n",
    "        beat_length = beat_lengths.pop()\n",
    "\n",
    "        beatmap_start_index = raw_content.index('[HitObjects]')\n",
    "        beatmap = raw_content[beatmap_start_index + 1:]\n",
    "\n",
    "        obj_list = []\n",
    "        xpos_set = set()\n",
    "\n",
    "        for obj in beatmap:\n",
    "            obj_split = obj.split(',')\n",
    "            time = int(obj_split[2])\n",
    "            xpos = int(obj_split[0])\n",
    "            xpos_set.add(xpos)\n",
    "\n",
    "            if obj_split[3] != '1': # If note is long note...\n",
    "                end_time = int(obj_split[5].split(':', 1)[0])\n",
    "                obj_list.append([time, xpos, 2, self.get_beat_phase(time, beat_length, offset)])\n",
    "                obj_list.append([end_time, xpos, 3, self.get_beat_phase(time, beat_length, offset)])\n",
    "            else:\n",
    "                obj_list.append([time, xpos, 1, self.get_beat_phase(time, beat_length, offset)])\n",
    "\n",
    "        xpos_list = sorted(xpos_set)\n",
    "        xpos2num = {xpos: num for num, xpos in enumerate(xpos_list)}\n",
    "\n",
    "        obj_list = [[obj[0], xpos2num[obj[1]], obj[2], obj[3]] for obj in obj_list]\n",
    "        obj_tensor = torch.tensor(obj_list, dtype=torch.float32)\n",
    "\n",
    "        # Sort by note time in ascending order\n",
    "        obj_tensor = obj_tensor[obj_tensor[:, 0].argsort()]\n",
    "\n",
    "        return len(xpos_list), obj_tensor\n",
    "\n",
    "    def convert_audio(self, y):\n",
    "        # Converts audio into 3-channel mel-spectrogram with context windows.\n",
    "        # INPUT: waveform of sr=44100\n",
    "        # OUTPUT: Tensor([num_timesteps, len_window * 2 + 1, 80, 3])\n",
    "\n",
    "        # Multiple-timescale STFT\n",
    "        specs = []\n",
    "        for converter in self.melspec_converters:\n",
    "            melspec = converter(y)\n",
    "            specs.append(torch.log(melspec.T))\n",
    "        specs = torch.stack(specs, dim=-1) # len X 80 X 3\n",
    "        min_value = torch.min(specs)\n",
    "\n",
    "        # Shift specs and stack\n",
    "        shifted_specs = []\n",
    "        for i in range(self.context_window_size, -self.context_window_size-1, -1):\n",
    "            shifted = torch.roll(specs, i, 0)\n",
    "            if i > 0:\n",
    "                shifted[:i, :, :] = min_value\n",
    "            elif i < 0:\n",
    "                shifted[i:, :, :] = min_value\n",
    "            shifted_specs.append(shifted)\n",
    "        shifted_specs = torch.stack(shifted_specs, dim=1) # len X 15 X 80 X 3\n",
    "\n",
    "        return shifted_specs\n",
    "\n",
    "    def find_file_by_stem(self, fn_list, stem):\n",
    "        for fn in fn_list:\n",
    "            if fn.stem == stem:\n",
    "                return fn\n",
    "        return -1\n",
    "\n",
    "    def convert(self):\n",
    "        # TODO: include beat phase\n",
    "\n",
    "        converted_audio_dir = self.data_dir / 'converted_audio/'\n",
    "        converted_audio_dir.mkdir(exist_ok=True)\n",
    "        converted_dirs = []\n",
    "\n",
    "        for osu_fn in tqdm(self.osu_fns):\n",
    "            # Parse beatmap notes\n",
    "            num_keys, beatmap = self.parse_beatmap(osu_fn)\n",
    "            if (num_keys == -1):\n",
    "                continue\n",
    "\n",
    "            converted_dir = self.data_dir / f'{num_keys}keys/'\n",
    "            if converted_dir not in converted_dirs:\n",
    "                converted_dir.mkdir(exist_ok=True)\n",
    "                converted_dirs.append(converted_dir)\n",
    "\n",
    "            # Check if corresponding audio has already been converted\n",
    "            audio_stem = osu_fn.stem.split('-')[0]\n",
    "            converted_audio_fn = self.find_file_by_stem(list(converted_audio_dir.glob('*.pt')), audio_stem)\n",
    "\n",
    "            if converted_audio_fn == -1:\n",
    "                # Load audio with OS-specific backend\n",
    "                audio_fn = self.find_file_by_stem(self.audio_fns, audio_stem)\n",
    "                if audio_fn == -1:\n",
    "                    print(f'Audio file not found: {audio_stem}')\n",
    "                    continue\n",
    "\n",
    "                if is_macos:\n",
    "                    y, sr = torchaudio.load(audio_fn, backend='ffmpeg')\n",
    "                else:\n",
    "                    y, sr = torchaudio.load(audio_fn)\n",
    "\n",
    "                y = y.mean(dim=0)\n",
    "                if sr != 44100:\n",
    "                    print(f'Sampling rate of file {audio_fn.name} is {sr}: Resampling to 44100.')\n",
    "                    y = torchaudio.functional.resample(y, sr, 44100)\n",
    "\n",
    "                converted_audio = self.convert_audio(y)\n",
    "\n",
    "                torch.save({'audio': converted_audio}, (converted_audio_dir / audio_fn.name).with_suffix('.pt'))\n",
    "\n",
    "            else:\n",
    "                converted_audio = torch.load(converted_audio_fn)['audio']\n",
    "        \n",
    "            torch.save({'audio': converted_audio, 'beatmap': beatmap}, (converted_dir / osu_fn.name).with_suffix('.pt'))\n",
    "\n",
    "# TODO: define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd833a3ceab48b49de5ac7179ab5d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([17879, 15, 80, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_dir = Path('../osu_dataset/original/')\n",
    "osu_dir = Path('../osu_dataset/original/')\n",
    "data_dir = Path('../osu_dataset/')\n",
    "\n",
    "converter = BeatmapConverter(audio_dir, osu_dir, data_dir)\n",
    "converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0, 101, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': tensor([[[-100.0000, -100.0000,  -95.2671],\n",
       "          [-100.0000, -100.0000,  -92.9380],\n",
       "          [-100.0000, -100.0000,  -66.2626],\n",
       "          ...,\n",
       "          [-100.0000,  -89.2753,  -81.3982],\n",
       "          [ -91.9179,  -86.1897,  -79.2755],\n",
       "          [ -90.5503,  -81.7363,  -78.3457]],\n",
       " \n",
       "         [[-100.0000, -100.0000,  -95.3818],\n",
       "          [-100.0000, -100.0000,  -89.9957],\n",
       "          [-100.0000,  -94.2618,  -68.4412],\n",
       "          ...,\n",
       "          [ -96.2452,  -87.9964,  -78.4766],\n",
       "          [ -87.9515,  -82.5127,  -76.0961],\n",
       "          [ -86.5839,  -80.1687,  -75.0421]],\n",
       " \n",
       "         [[-100.0000,  -99.9394,  -88.9389],\n",
       "          [ -96.5777,  -97.3742,  -85.9001],\n",
       "          [ -89.7557,  -87.3100,  -72.2434],\n",
       "          ...,\n",
       "          [ -85.5498,  -82.3821,  -76.9738],\n",
       "          [ -84.3724,  -80.0587,  -76.1759],\n",
       "          [ -96.4257,  -83.0936,  -76.0197]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ -66.9830,  -59.5089,  -52.5555],\n",
       "          [ -63.9295,  -58.2663,  -52.4623],\n",
       "          [ -63.2848,  -58.0078,  -52.2732],\n",
       "          ...,\n",
       "          [ -66.4563,  -59.7071,  -53.3710],\n",
       "          [ -65.4073,  -59.4046,  -53.2081],\n",
       "          [ -64.9213,  -58.7425,  -53.1329]],\n",
       " \n",
       "         [[ -67.9064,  -58.8466,  -52.6244],\n",
       "          [ -63.2346,  -58.4676,  -52.5580],\n",
       "          [ -66.4645,  -58.8233,  -52.4372],\n",
       "          ...,\n",
       "          [ -64.8128,  -58.6416,  -52.8194],\n",
       "          [ -63.1189,  -58.3233,  -52.9412],\n",
       "          [ -68.1301,  -60.3392,  -53.0691]],\n",
       " \n",
       "         [[ -65.5883,  -57.3243,  -51.0386],\n",
       "          [ -61.7611,  -56.7672,  -51.2038],\n",
       "          [ -62.9632,  -57.3422,  -51.7458],\n",
       "          ...,\n",
       "          [ -63.4940,  -58.1007,  -52.5184],\n",
       "          [ -63.8169,  -58.2679,  -52.6310],\n",
       "          [ -67.5934,  -59.6756,  -52.7417]]]),\n",
       " 'beatmap': tensor([[    0.0000,     0.0000,     3.0000,     0.0000],\n",
       "         [  639.0000,     0.0000,     2.0000,     0.0000],\n",
       "         [  893.0000,     1.0000,     1.0000,     0.4995],\n",
       "         ...,\n",
       "         [173775.0000,     1.0000,     2.0000,     0.5008],\n",
       "         [174029.0000,     3.0000,     3.0000,     0.9993],\n",
       "         [174029.0000,     1.0000,     3.0000,     0.5008]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('../osu_dataset/4keys/1019836-189-4.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
