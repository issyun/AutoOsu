{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note Placement Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "is_macos = platform == 'darwin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeatmapDataset:\n",
    "    def __init__(self, audio_dir, osu_dir, data_dir):\n",
    "        audio_fns = sorted([p for p in Path(audio_dir).glob('**/*') if p.suffix in {'.mp3', '.wav', '.ogg'}])\n",
    "        osu_fns = sorted(list(Path(osu_dir).rglob('*.osu')))\n",
    "        self.data_fns = list(zip(audio_fns, osu_fns))\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def parse_beatmap(self, fn):\n",
    "\n",
    "        # TODO: calculate beat phase\n",
    "\n",
    "        with open(fn, mode='r', encoding='utf-8') as f:\n",
    "            raw_content = f.read().splitlines()\n",
    "        start_index = raw_content.index('[HitObjects]')\n",
    "        beatmap = raw_content[start_index + 1:]\n",
    "\n",
    "        obj_list = []\n",
    "        xpos_list = set()\n",
    "        xpos2num = {}\n",
    "\n",
    "        for obj in beatmap:\n",
    "            obj_split = obj.split(',')\n",
    "            time = int(obj_split[2])\n",
    "            xpos = int(obj_split[0])\n",
    "            is_longnote = obj_split[3] != '1'\n",
    "            end_time = obj_split[5].split(':', 1)[0] if is_longnote else 0\n",
    "\n",
    "            obj_list.append([time, xpos, int(is_longnote), int(end_time)])\n",
    "            xpos_list.add(xpos)\n",
    "\n",
    "        xpos_list = sorted(xpos_list)\n",
    "        xpos2num = {xpos: num for num, xpos in enumerate(xpos_list)}\n",
    "\n",
    "        obj_list = [[obj[0], xpos2num[obj[1]], obj[2], obj[3]] for obj in obj_list]\n",
    "\n",
    "        obj_tensor = torch.LongTensor(obj_list)\n",
    "\n",
    "        return obj_tensor\n",
    "    \n",
    "    def shift_cat_audio(self, y, shift_amount):\n",
    "        tensor_list = []\n",
    "        for shift in range(shift_amount, 0, -1):\n",
    "            shifted = y.\n",
    "\n",
    "    def convert_spec(self, n_fft_list:list=[1024, 2048, 4096], hop_ms:int=10, n_mels:int=80):\n",
    "\n",
    "        # TODO: split melspec into 15 sample windows\n",
    "        # TODO: include beat phase\n",
    "\n",
    "        melspec_converters = [ torchaudio.transforms.MelSpectrogram(sample_rate=44100, n_fft=n_fft, hop_length=int(44100*(hop_ms/1000)), f_max=11000, n_mels=80) for n_fft in n_fft_list ]\n",
    "        db_converter = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "        for audio_fn, osu_fn in self.data_fns:\n",
    "            if is_macos:\n",
    "                y, sr = torchaudio.load(audio_fn, backend='ffmpeg')\n",
    "            else:\n",
    "                y, sr = torchaudio.load(audio_fn)\n",
    "            y = y.mean(dim=0)\n",
    "            \n",
    "            if sr != 44100:\n",
    "                print(f'Sampling rate of file {audio_fn.name} is {sr}: Resampling to 44100.')\n",
    "                y = torchaudio.functional.resample(y, sr, 44100)\n",
    "            \n",
    "            # Multiple-timescale STFT\n",
    "            specs = []\n",
    "            for converter in melspec_converters:\n",
    "                melspec = converter(y)\n",
    "                specs.append(db_converter(melspec))\n",
    "            specs = torch.stack(specs, dim=-1)\n",
    "\n",
    "            # Parse beatmap\n",
    "            print(osu_fn)\n",
    "            beatmap = self.parse_beatmap(osu_fn)\n",
    "\n",
    "            torch.save({'specs': specs, 'beatmap': beatmap}, (self.data_dir / osu_fn.name).with_suffix('.pt'))\n",
    "\n",
    "    # TODO: getitem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/er.osu\n"
     ]
    }
   ],
   "source": [
    "dataset = BeatmapDataset(Path('data/'), Path('data/'), Path('data/converted'))\n",
    "dataset.convert_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 8778, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs, beatmap = torch.load('data/converted/er.pt').values()\n",
    "specs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
